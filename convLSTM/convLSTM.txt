ConvLSTM v0.4 – California Coastal Harmful Algal Bloom (HAB) Forecasting
========================================================================
This document details every methodological component of the ConvLSTM **v0.4**
baseline used to forecast chlorophyll‑a (proxy for HABs) 8 days in advance
along the ~10‑mile near‑shore strip of the California coast.

---------------------------------------------------------------------------
1. DATASET & PRE‑PROCESSING
---------------------------------------------------------------------------
• **Analysis‑ready dataset**: `HAB_convLSTM_core_v1_clean.nc`
  – Spatial grid : 4 km (~0.04°) | Domain = 32.5°–42.0° N,  −125.0°–−117.0° E  
  – Temporal span: 2003‑01‑01 → 2021‑06‑30 (daily composites)  
  – Total timesteps: 6 760

• **Predictor groups (30 variables total)**
  SATELLITE : log_chl, Kd_490, nflh  
  METEO     : u10, v10, wind_speed, tau_mag, avg_sdswrf, tp, t2m, d2m  
  OCEAN     : uo, vo, cur_speed, cur_div, cur_vort, zos, ssh_grad_mag, so, thetao  
  DERIVED   : chl_anom_monthly, chl_roll24d_mean/std, chl_roll40d_mean/std  
  STATIC    : river_rank, dist_river_km, ocean_mask_static

• **Chlorophyll transformation**  
  Raw chl (mg m⁻³) ➔ log‐space with constant detection floor  
  _FLOOR_ = 0.056 616 mg m⁻³  
  log_chl = log(chl_lin + FLOOR)

• **Quality masks**  
  – `pixel_ok`: ≥20 % valid observations over the record  
  – Shallow‑water mask: depth ≤ 10 m (bays & estuaries) excluded from loss

• **Time splits**  
  Train < 2016‑01‑01 | Val 2016‑01‑01…2018‑12‑31 | Test > 2018‑12‑31  
  (lead‑time shift applied _after_ split)

• **Sequence / Lead**  
  SEQ = 6 frames = 48 d history | LEAD = 1 frame = +8 d forecast

• **Patch sampling**  
  Random 64 × 64 pixel crops (~256 km × 256 km) drawn per step  
  Corner chosen until ≥1 valid cell in mask (max 20 tries).

• **Stratified temporal sampler**  
  – Domain‑median chl computed per timestep; binned into quartiles  
  – Bin frequencies **freq**; sample weights ∝ freq^‑1.5  
  – Implemented via `WeightedRandomSampler` over training indices.

• **Normalisation**  
  Per‑variable μ, σ computed on _train_ split → z‑scores on‑the‑fly.

---------------------------------------------------------------------------
2. MODEL ARCHITECTURE
---------------------------------------------------------------------------
Input  : (B, SEQ, C_in, H, W) where C_in = ⟨present predictors⟩ (=30 here)  
Output : Δ(log_chl) field (B, H, W) added to last frame for final forecast.

 ┌─ 1 × 1 Conv C_in → 24              (#params ≈ 24·C_in + 24)
 │
 ├─ **Pixel‑wise LSTM ‑ Layer 1**  
 │   LSTMCell( in=24, hidden=48 ) + 1 × 1 Conv 48→48  
 │   (applied identically at every pixel; spatial weight‑sharing)
 │
 ├─ **Pixel‑wise LSTM ‑ Layer 2**  
 │   LSTMCell( in=48, hidden=64 ) + 1 × 1 Conv 64→64
 │
 └─ 1 × 1 Conv head 64 → 1           (predicted Δlog)

Total parameters: **≈ 225 k** (exact: 224 833 with 30 predictors)

---------------------------------------------------------------------------
3. TRAINING PROCEDURE
---------------------------------------------------------------------------
• Optimiser   : AdamW (lr = 3 × 10⁻⁴, weight_decay = 1 × 10⁻⁴)  
• Batch size  : 32 (fits on 12 GB GPU, mixed precision)  
• Epochs max  : 40 (early‑stop patience = 6 epochs)  
• Scheduler   : ReduceLROnPlateau (mode =min, patience = 3, factor = 0.5)  
• Gradient clip : L2‑norm 1.0  
• AMP / FP16  : Enabled when CUDA available (`torch.cuda.amp`)  
• Seed     : 42 (Python, NumPy, Torch)

Loss = **Class‑weighted Huber** on Δ(log_chl):
  – Huber δ = 1.0  
  – Class weights (per‑pixel, per‑timestep) from linear‑chl quartiles:  
      <Q1 → 1.0 | Q1‑Q2 → 1.5 | Q2‑Q3 → 2.5 | ≥Q3 → 4.0  
  – Mask multiplies weights so shallow/bad pixels contribute 0.

Target = `y − last_log_chl`; model predicts residual.

---------------------------------------------------------------------------
4. EVALUATION & DIAGNOSTICS
---------------------------------------------------------------------------
Primary metric : RMSE_log (log‑space) on valid mask  
Secondary      : MAE_log, RMSE/MAE in mg m⁻³, skill vs persistence  
                 Skill (%) = 100 × (1 − RMSE_model / RMSE_persistence)

Bias correction : constant log‑bias (mean error over all val + test pixels)
                  subtracted from predictions before metrics/plots.

Outputs (03_diagnostics.py):
  • `metrics_global.csv` (train/val/test/all)  
  • `metrics_month.csv` (seasonality)  
  • `metrics_bins.csv`  (bloom quartiles)  
  • Spatial RMSE & skill maps (`skill_maps.npz`, PNG)  
  • Domain‑mean time‑series & scatter, residual histograms  
  • Full 3‑D predicted field NetCDF (`predicted_fields.nc`)

---------------------------------------------------------------------------
5. RESULTS SUMMARY (latest runs)
---------------------------------------------------------------------------
Ver 1 SEQ=4, old sampler / L1 loss  
  Train 0.764 | Val 0.734 | Test 0.766 (RMSE_log)

Ver 2 SEQ=6, new stratified sampler, Huber‑weighted  
  Train 0.761 | Val 0.705 | Test 0.803

Ver 3 SEQ=6, Huber Δ=1.0, shallow‑mask tweak  
  Train 0.751 | Val 0.709 | Test 0.805

---------------------------------------------------------------------------
6. RUNTIME ENVIRONMENT
---------------------------------------------------------------------------
• Python 3.10, PyTorch 2.2  
• Hardware : NVIDIA RTX‑A2000 (12 GB) – mixed precision enabled  
• OS        : macOS 13 / Ubuntu 22.04 (container)  
• Repro   : all paths configurable via CLI; checkpoints loaded with
             `strict=True` against detected variable list.

---------------------------------------------------------------------------
7. NOVEL CONTRIBUTIONS vs v0.3
---------------------------------------------------------------------------
✔ Extended history window (32 → 48 days) improves spring upwelling skill  
✔ Stratified temporal sampler with power‑law weights addresses class imbalance  
✔ Class‑weighted Huber emphasises bloom & extreme events while remaining robust  
✔ Shallow (<10 m) & bay pixels excluded from loss ⇒ better coastal generalisation  
✔ Bias‑corrected diagnostics & richer metric suite (quartile, season, maps)

---------------------------------------------------------------------------
8. LIMITATIONS / NEXT STEPS
---------------------------------------------------------------------------
• Pixel‑wise LSTM lacks explicit spatial advection; explore ConvLSTM2D / PINNs  
• Present sampler ignores spatial imbalance (future: joint spatio‑temporal strata)  
• Detection floor constant across domain—may refine with optical depth model  
• No exogenous event flags (e.g., river discharge spikes) yet included  
• Multi‑lead training (self‑conditioning) under investigation.

---------------------------------------------------------------------------
END OF FILE